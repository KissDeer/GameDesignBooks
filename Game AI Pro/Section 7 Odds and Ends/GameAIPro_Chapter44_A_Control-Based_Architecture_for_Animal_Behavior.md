# 七杠二、基于控制的动物行为架构



作者：Michael Ramsey

## 44.1 引言



许多游戏中都包含生物或动物，它们在与玩家和周围世界互动时呈现出生命的假象。然而，当一个生物做出不符合其性格或不自然的行为时，这种假象就会被打破，而这类假象的破灭在游戏中非常普遍。因此，我们需要让角色能够表现出可信的、有目的的行为，并且足够稳健，使其看起来完全栩栩如生。



在本文中，我们将行为定义为智能体执行的动作。有目的的行为是指在某个目标背景下执行的动作（例如，走向食盆进食或爬上树在树枝上睡觉）。有许多著名的架构可以生成一系列行为并将它们串联起来以实现有目的的行为（例如行为树（BTs）、有限状态机（FSMs）、分层任务网络规划器（HTNs）等），本书的其他部分也讨论了其中许多架构。然而，如果我们的行为要令人信服，它就不能仅仅是行为树或其他 AI 架构的输出。它需要一个能够在不断变化的游戏情境中提供适当交互的系统。



如果有目的的行为要令人信服，那么无论环境条件如何变化，它都必须产生一致的结果。这是现实世界中的生物通常无需太多思考就能处理的事情，但对于 AI 角色来说却相当困难。例如，想想像穿过房间去按灯开关这样简单的动作所涉及的一系列动作。它们会因你的起始位置和姿势、灯开关的准确位置、两者之间障碍物的类型和位置、所经过的表面类型等因素而有很大差异。



1890 年，美国心理学家威廉・詹姆斯（William James）对适应性、有目的的行为进行了很好的描述 [James 90]：
“罗密欧渴望朱丽叶，就像铁屑渴望磁铁；如果没有障碍物阻挡，他会像铁屑一样径直向她走去。但是，如果在罗密欧和朱丽叶之间筑起一堵墙，他们不会像磁铁和铁屑隔着卡片那样愚蠢地把脸贴在墙的对面。罗密欧很快就会找到一条迂回的路，比如翻墙，直接亲吻朱丽叶的嘴唇。”



威廉・詹姆斯对罗密欧行为的描述为我们在虚拟角色方面的工作提供了关于有目的行为的直觉。就像罗密欧和朱丽叶一样，我们的行为建模解决方案需要考虑和应对世界的可变性，并相应地进行适应 —— 所以当需要亲吻时，无论需要穿过舞池、爬上阳台还是仅仅弯腰捡起匕首，我们都能实现。



《动物园世界》就是一个可能会因行为的可信度问题而受到影响的游戏示例。这是一款动物模拟游戏，在各种环境中包含了不同类型的动物园动物。玩家可以改变动物园的布局，从而改变动物周围的环境。在最坏的情况下，这可能会导致动物游戏世界的大规模拓扑结构改变，直接干扰动物的当前行为！这实际上并不罕见，因为玩家很少会围绕动物的行为来规划他们的改变，在某些情况下甚至会故意 “捣乱”。因此，动物需要能够对环境的变化做出可信的反应，这些变化在开发过程中设计行为时甚至在高级 AI 选择行为时都是无法预测的。



本章的其余部分将介绍可用于实现逼真动物行为系统的控制器理论方面的内容。

## 44.2 控制系统



即使对物理世界进行最简单的观察也表明环境并非静止不变的。没有固定的、预先确定的行为能够让动物应对这个世界，因此行为必须以某种方式考虑到不断变化和不可预测的世界。显然，我们的动物 AI 必须不断修改其行为以适应那些会使预先确定的行为看起来不正确的干扰 —— 但是我们如何以及在哪里找到合适的修改方式呢？



20 世纪 30 年代早期，电气和机械工程师在控制理论这一学科中的工作为我们提供了一种解决方案。以行为为中心的方法认为世界是通过动物的行为受其控制的，而控制理论则认为动物受世界的支配，但能够通过控制系统改变其行为以补偿世界的变化。这些系统的例子在各种电子设备中都能找到，比如家中调节供暖或制冷系统的恒温器，甚至海军舰艇上的自动高射炮。



为了帮助我们理解控制系统是什么，我们从控制系统的高级模型开始。从根本上说，这些系统要做四件事：



1. 接收信号。
2. 分析信号。
3. 根据分析后的信号发出指令。
4. 这些指令用于在世界或另一个控制系统中执行某些操作。



车辆巡航控制系统在没有驾驶员输入的情况下保持稳定行驶速度就是这种控制系统的一个很好的实际例子。当巡航控制系统设定了特定的期望速度时，这个速度就成为控制系统的参考信号（也是系统的期望目标）。如果车辆速度偏离目标，控制系统就会增加或减少输送到发动机的燃油量，从而调整速度，直到再次与目标匹配。因为这个系统旨在最小化实际值和目标值之间的差异，所以它被称为负反馈系统。在本章的其余部分，我们将重点关注负反馈系统。

## 44.3 感知控制系统 —— 负反馈



如图 44.1 所示，负反馈可以想象成一个弯曲杯子里的弹珠。杯子底部代表我们的参考信号 —— 即我们想要保持的值。就像重力一样，控制系统不断将实际值拉向杯子底部，直到它与最低点的目标值匹配。当外力将实际值推离我们的期望价值时（想象一下左右移动杯子或用手指将弹珠向上弹起），负反馈会将其再次拉回来。



图 44.2 展示了负反馈系统的更详细实现方式。输入函数将世界的某些可变方面转换为感知信号。然后，感知信号在比较器函数中与参考信号进行比较。两者之间的差异，称为误差信号，然后在输出函数中转换为一种行为。还可以对输出应用增益因子。增益调整我们输出行为的幅度 —— 例如，在巡航控制的情况下，它会改变加速或减速的速率。



经过增益调整的行为作用于世界，以期望的方式改变它。然而，系统所控制的变量不仅受到系统输出的影响 —— 它仍然受到世界不断变化的状态的影响。因此，我们不断重新检查世界的状态，将其输入控制系统，然后根据控制系统的输出修改我们的行为，试图使变量尽可能接近参考信号。



回到巡航控制的例子，我们看到巡航控制系统有许多组件，能够展示出有目的的行为 —— 即使在干扰未知的情况下，这种行为也能被视为对干扰的补偿。控制系统不知道车辆是在上坡还是下坡、是否拖着露营车、是否有风阻或发动机是否完全正常工作。这个控制系统所了解的世界的唯一方面是车辆的速度和输送到发动机的燃油速率。在这种情况下，车辆的速度是受控变量；然而，控制系统并不直接控制其值，而是控制它如何变化。巡航控制系统感知车辆的速度，它唯一的控制手段是调整燃油流量。为了维持目标（设定为参考信号），控制系统必须在干扰试图改变控制系统输入时继续感知车辆的速度。随着车辆周围条件的变化，任何干扰都会得到补偿，表现出的行为也会改变。



虽然我们在为用户自动化一个过程的背景下讨论了控制系统，比如驾驶员设定巡航控制的期望速度，但需要强调的是，参考水平不一定在游戏进行时定义；初始值可以由设计师在开发过程中指定，然后在必要时随着游戏的进展进行更新。

## 44.4 控制系统的层次结构



1989 年，威廉・鲍尔斯（William Powers）提出了一个包含 11 个有序层次的复杂控制系统层次结构，作为人类和动物感知的基础 [Powers 89]。这种方法的细节对于我们的动物 AI 来说过于复杂，但总体概念非常有用。关键思想（见图 44.3）是高阶控制系统调整低阶系统的参考信号，低阶系统所感知的输入也可供高阶系统使用。系统中较高层次组件的感知通常由低阶系统的组合构成，然后由高阶系统通过改变它们的参考水平来控制。通过这种方式，我们不是创建一个命令层次结构；相反，我们让高阶系统调整低阶系统的参考值，然后这些低阶系统直接输出适当的行为。



再次回到巡航控制的例子，一些较新的汽车有 “智能巡航控制” 功能，在跟随另一辆车时会自动减速。这可以通过在系统中添加一个更高层次的层来实现。新层接收来自现有组件（当前速度）的输入，但它也考虑所控制的汽车与前面车辆的跟随距离。这个新组件的输出是低阶系统的参考值 —— 也就是说，它会自动调整巡航控制的期望速度以减速并避免碰撞。

## 44.5 动物行为的控制系统



虽然许多动物似乎只表现出简单的刺激和反应机制，但对动物心理学的研究发现，动物的许多行为远比执行 if/then/else 测试复杂得多。海尼・赫迪格（Heini Hediger）对动物自然环境中的防御行为进行了首批研究之一 [Hediger 55]。赫迪格首次描述了逃跑区域。关键思想是，动物不会一看到捕食者就逃跑，而是会等到捕食者接近到特定距离内，此时受到威胁的动物会移动以重新创造期望的空间。在赫迪格的工作中，我们看到防御不仅仅是对刺激的反射性反应，而是一个持续的空间评估和移动过程。这些持续执行和评估的系统本质上就是控制系统。

## 44.6 定制负反馈控制器 —— 游戏扩展



上述巡航控制系统侧重于使用一个或最多两个控制器管理单个浮点控制变量（车辆速度）。动物需要能够做的不仅仅是以固定速度沿着直线路径移动，因此它们需要更复杂的输入和更多的控制器。因此，我们需要提供一个定制的负反馈控制器实现，它作用于粗糙的数据结构 / 对象 [Ramsey 09, Ramsey 10]。适用于动物控制的控制器示例包括上述逃跑区域控制器、个人空间控制器、生理需求控制器（例如食物、水或睡眠 [Toda 82]）和环境空间方向控制器 [Ramsey 11]。



也许最重要的定制是提供 “空间语义” 的表示。换句话说，我们需要能够向控制系统的输入表示关于位置的概念。这些概念的示例包括附近食物源的位置、附近障碍物的位置、其他实体（友好或敌对）的位置等等。比较器然后可以以类似的方式工作 —— 检查输入信号（也许是动物的当前位置），将其与参考信号（也许是靠近附近食物源的位置）进行比较，并返回适当的行动（例如走向食物源并进食）。



对控制器模型的另一个重要修改是添加优先级值。这在很大程度上取决于你制作的游戏类型，但一般来说，如果一个控制系统的优先级相对较低，其输出可能会被优先级更高的另一个控制系统的输出所取代。下面将更清楚地说明这一点。

## 44.7 小鹅控制系统



此时，我们拥有了创建一个逼真的小鹅模拟所需的所有构建块，展示了它与小世界进行可信交互的一些有趣方式。



构建行为系统的一种方法是为我们的虚拟动物赋予各种各样的驱动力、需求或冲动 [Toda 82]。这些动机在开发过程中可由设计师修改，在游戏运行时也可由游戏修改，这使我们能够影响高阶控制系统的当前状态。在我们的示例中，我们将为小鹅分配两个在示例世界中相关的驱动力：安全和好奇心。



康拉德・洛伦兹（Konrad Lorenz）发现，小鹅会对它看到的第一个大型活动物体产生印记，通常是它的母亲 [Lorenz 81]。这种印记启动了一个控制系统，要求小鹅在整个幼年时期与母亲保持密切接触，通过监测这个距离并移动以补偿检测到的任何干扰。在自然界中，这些干扰可能是由母亲的行动引起的，比如离开，或者是由障碍物阻止小鹅直接接近母亲。



当然，小鹅除了简单地待在母亲附近之外还会做其他事情。它们还会寻找食物、躲避捕食者和探索周围环境等等。单独来看，这些事情中的每一件都可以用一个负反馈控制系统相当简单地建模。所以我们有一个控制系统负责维持与母亲的距离；另一个试图向附近的食物移动（并进食）；第三个试图躲避捕食者；第四个试图寻找小鹅尚未检查过的东西 —— 树木、岩石、花朵或它从未去过的区域。



每个系统都获取小鹅的当前位置，并试图根据输入信号（最近食物的位置、附近捕食者的位置等等）调整这个位置。关键在于决定这四个控制器在任何给定时间应该实际控制小鹅 —— 这就是优先级发挥作用的地方。每个控制器根据其当前的紧急程度被分配一个优先级。所以寻找母亲的控制器的优先级会根据母亲的距离远近而变低或变高。寻找食物的控制器的优先级取决于小鹅的饥饿程度。躲避捕食者的控制器优先级非常高，但只有在捕食者进入逃跑区域时才会如此。最后，探索的控制器优先级相对较低，但始终处于活动状态。

## 44.8 结论



本章介绍了如何使用负反馈控制器来生成考虑游戏世界环境动态特性的动物行为。这些控制系统利用环境中的空间语义作为输入，并将其与设计师指定的参考信号进行比较。然后，它能够生成用于驱动动物活动的误差信号。仅仅将独立的预定行为拼接在一起是不够的；我们需要一个底层机制，通过与环境的相互作用，能够对动物的期望（参考）状态采取纠正措施，而这可以被视为一种行为。