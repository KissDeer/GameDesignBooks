二杠十一、使用 LOD Trader 实现卓越的 AI 细节等级控制
本・阳光 - 希尔
14.1 引言
在所有使现代视频游戏图形成为可能的技术中，细节等级（LOD）管理很可能是最重要、最具开创性和最能改变游戏的。虽然 LOD 看起来像是一个相当无聊的 “开创性” 事物，但为了在我们想要的世界大小中获得我们想要的图形质量，不将所有东西都渲染得好像玩家离它只有两厘米远是至关重要的。通过保守选择的 LOD 转换距离，可以在不损害场景真实感的情况下实现巨大的加速。从广义上讲，甚至像可见性剔除这样的事情也可以被视为 LOD 的一部分 —— 毕竟，一个物体的最低细节可能是根本不渲染它。图形程序员依赖 LOD。从某种意义上说，这就是 “图形的工作方式”。
当然，AI 程序员也使用某种形式的 LOD，但我们并不真正依赖它。我们会为距离超过十米的角色使用较低质量的移动和碰撞避免系统，或以较低的更新率模拟视野外的角色，或者（类似于上面的可见性剔除）在角色距离太远时完全删除它们。但是，虽然图形程序员可以使用 LOD 而不损害真实感，但每当我们使用 LOD 时，在我们的脑海中，我们的良心会低语：“这只是一个黑客…… 有人会注意到的。” 我们只在绝对必要时使用 LOD，因为我们知道它会降低我们 AI 的质量。
我们不依赖 AI LOD 还有另一种意义。在图形中，LOD 是场景复杂性的自然限制。玩家一次只能靠近这么多物体，而所有不在玩家附近的物体渲染成本更低，因此帧率往往会趋于平衡。当然，这远不是一种保证，但 LOD 是维持帧率的第一道防线。然而，对于 AI 来说，我们真正想要使用的技术通常不可能同时在少数几个 NPC 上运行，并且一群 NPC 很容易超出我们的 CPU 时间预算。我们无法选择一个 “LOD 阈值距离”，既能尊重我们的预算，又能为大多数可见角色提供我们想要的细节。
所以我们使用 LOD。但它不是 “AI 的工作方式”。
如果 LOD 更智能呢？如果它甚至不使用距离，而是能够以不可思议的精度确定每个角色对玩家的 “重要性” 呢？如果它能够读懂玩家的心思，并告诉游戏何时开始为角色使用高质量的碰撞避免，何时停止呢？如果它知道玩家记得哪些角色，忘记了哪些角色呢？如果它的 LOD 选择总是在 NPC 决定聚集在玩家周围时尊重 CPU 时间预算，但在它们不聚集时总是充分利用可用时间呢？
那么，我们可以信任 LOD。我们可以使用我们想要的昂贵技术，因为我们可以依靠 LOD 来防止它们超出我们的预算。我们可以摆脱调整 LOD 阈值的无休止任务，以及硬编码一个又一个的黑客来补偿我们的 LOD 阈值不足的无数特殊情况。LOD 可以成为 “AI 的工作方式”。
简而言之，这就是 LOD Trader。它不能读懂玩家的心思，但它简单的启发式算法在确定一个角色对玩家的重要性方面比距离阈值要先进得多。它不依赖于固定的转换规则，而是将我们想要控制的所有 AI 功能的细节等级的整个空间视为一个每帧都要解决的谜题。它试图在不超出计算预算的情况下最大化游戏模拟的真实感，并且在非常短的时间内（几十微秒）完成。
它并不神奇。它的启发式算法远非万无一失，其 LOD 解决方案的最优性只是近似的。但它远远超出了基于距离的 LOD，当它第一次比你更聪明 —— 它的 LOD 减少变得微妙然后不可见时 —— 你会感到有点惊讶。
14.2 定义问题
当解决 “最优 LOD 选择” 这样的问题时，我们首先要做的是弄清楚我们所说的最优是什么意思。图形程序员不需要这样做，因为他们的 LOD 选择可以是完美的 —— 他们可以在足够远的距离进行转换，以至于不会放弃任何真实感。但是我们所做的每一个细节减少都可能会降低真实感，所以我们需要从数字意义上定义我们试图最大化的东西以及我们的约束是什么。我们需要想出一个指标，一个用于测量真实感的单位系统。哎呀。
好吧，让我们抓住问题的关键。我声称我们试图为每个角色的每个 AI 功能选择一个细节等级，以最小化玩家注意到问题的概率，即细节的不真实减少。这有助于确定事情，因为我们都知道所有关于概率的知识，以及如何比较它们并进行算术运算。在这个模型中，选择 A 不会比选择 B “稍微不真实”，而是会 “稍微不容易被注意到”。我们将玩家实际注意到问题的事件称为现实中断（BIR）。只有当玩家注意到问题时，BIR 才会发生；如果她没有注意到实体的细节减少是不真实的，那么仅仅减少实体的细节并不是 BIR。
14.2.1 深入 X 空间
不过，让我们让事情变得更聪明一些。假设用户注意到某个实体不真实的概率为 P。我们不直接使用这个数字，而是使用数字。这是概率补集的负对数（无论使用什么底数，让我们使用传统的 e）—— 用户没有注意到的概率，即侥幸逃脱的概率。P 与 x 的关系图如图 14.1 所示。随着 P 的增加，x 也增加。如果 P 为零，x 为零；当 P 接近 1 时，x 接近无穷大。（逆方程为。）
为什么要这么复杂？实际上，这是一种简化；事实证明，x 比 P 表现得更好。首先，如果我们有两个潜在的不真实事件源，被注意到的（独立）概率为和，我们想知道用户注意到其中任何一个的总概率，那就是，不是特别好。对于三个源，情况会更糟：相比之下，。其次，这种转换使我们更好地解释诸如 “不真实程度是原来的两倍” 这样的短语。如果某个事件被注意到的概率为，而另一个事件 “不真实程度是的两倍”，那么它的概率是多少？显然它不能是 1.2—— 那不是一个有效的概率。但是在 x 空间中，事情解决得很好：，这导致，，。0.84 是什么？如果第一个事件发生两次，这是每次注意到它的概率。能够以这种直观的方式描述概率之间的相对关系非常有用，因为这比确定绝对概率要容易得多。x 空间为我们提供了表现良好的加法和乘法，这（正如我们稍后将看到的）对 LOD Trader 至关重要。实际上，几乎没有什么理由使用 P。
14.3 关键性和概率
接下来我们要看的是我们所说的角色的关键性。这代表了角色的真实感对整个场景的真实感的 “关键” 程度，或者，如果你愿意，玩家对角色细节等级的关键程度。从某种意义上说，这就是我们使用基于距离的 LOD 时距离所代表的：在其他条件相同的情况下，较近的角色比较远的角色对场景更关键。
但其他条件并不相同。在确定关键性时，还有其他因素可以使用。如果我们能够连接眼动仪、脑电图和通灵板来了解玩家的想法，那将是很棒的，但即使没有这些，我们也可以从游戏中提取大量指标来帮助估计给定实体在给定时间对玩家的关键性。
然而，在我们进一步深入之前，有一件关于 BIR 和关键性的非常关键的事情需要意识到：并非所有的不真实都是相同的。考虑两个角色。一个是玩家一直在远处跟踪的疑似刺客。另一个是在玩家前方几英尺处过马路的随机村民。从某种意义上说，两个角色都很重要。第一个角色显然是玩家有意识关注的对象；如果我们只能为一个角色提供高质量的路径规划，最好是那个角色，因为如果他随机游荡，玩家更有可能注意到。但是第二个角色占据了更多的屏幕空间，可能也占据了玩家更多的视觉注意力 —— 如果我们只能为一个角色提供高质量的移动 IK，那么可能应该是那个角色。
14.3.1 BIR 的分类指南
在这一点上，很容易认输，得出结论，BIR 的种类与我们想要调整其细节等级的 AI 功能的数量一样多。但我认为几乎所有的 BIR 都可以归入一小部分类别。任何给定的细节减少都将在至少一个这些类别中产生 BIR 的可能性，有时甚至更多。对事物进行这样分类的原因是因为每个 BIR 类别都可以有自己的关键性模型。
14.3.1.1 不真实状态
不真实状态（US）BIR 是最直接和明显的 BIR 类型，其中角色的即时可观察模拟是错误的。一个角色从空盘子里吃东西，或在墙上原地跑步，或头上戴着水桶，都有可能导致不真实状态 BIR。（请注意，这不是确定的 —— 玩家可能没有看。）US 不需要任何长时间的观察，只需要瞬间的注意，而且注意不一定是自愿的 —— 眼睛往往会被这样的事情吸引。
14.3.1.2 基本不连续性
基本不连续性（FD）BIR 稍微微妙一些，但也不是很多：当角色的当前状态与玩家对其过去状态的记忆不兼容时，就会发生这种情况。一个角色在瞬间转过拐角后消失，或在玩家离开时被冻结在原地几个小时，或重新使用已经折断的肢体，都有可能导致基本不连续性 BIR。当然，这些情况也可能导致 US BIR。但是，即使角色在发生这些情况时没有被观察到，只要玩家记得旧状态并后来返回，FD BIR 的可能性仍然存在。
14.3.1.3 不真实的长期行为
不真实的长期行为（ULTB）BIR 是最微妙的：只有当长时间的观察揭示出角色行为的问题时，它才会发生。一个角色随机游荡而不是有目标驱动的行为是不真实的长期行为 BIR 的最常见例子，但一辆永远不会耗尽汽油的汽车也是如此。在任何给定时间，只有少数角色可能容易出现 ULTB BIR。
14.4 建模关键性
让我们来为这些不同的类别建立关键性模型。每个模型都将几个因素的乘积计算为关键性得分，其中一些因素在多个模型中共享。
对于不真实状态，因素是可观察性和注意力。可观察性最接近图形 LOD：它衡量玩家看到相关角色的可行性。注意力是不言而喻的：它估计玩家对特定角色的关注程度。正如你可能猜测的那样，这是最难估计的因素。
对于基本不连续性，两个相关因素是记忆和返回时间。记忆估计玩家对角色的事实记忆的有效程度，以及他们注意到角色变化的可能性。返回时间作为记忆因素的修饰符：它估计当玩家返回角色时，玩家对角色的记忆会减弱多少，甚至她是否会返回。
对于不真实的长期行为，三个因素是注意力、记忆和持续时间。注意力和记忆已经介绍过（请注意，返回时间因素在这里不对记忆起作用）；最后一个，持续时间，简单地指玩家投入到该角色的时间和注意力。
这就是角色。现在让我们为每个角色想出实际的方程。请注意，后面的因素通常会在其输入中使用前面的因素；我们列出它们的顺序是计算它们的好顺序。
不过，在我们进入这些之前，我们需要介绍一个将在许多方程中使用的工具：指数移动平均（EMA）。EMA 是一种用于平滑和平均正在进行的一系列测量的方法。给定输入函数，我们生成输出函数。我们初始化，然后在每个时间，我们更新为，其中是自上次测量以来的时间步长。该方程中的计算为，其中是收敛率（更高的值导致平均值的变化更快）。你可以调整来改变 EMA 的平滑度，以及它跟踪输入函数的紧密程度。我们将在这些模型中大量使用 EMA，所以熟悉它是个好主意（图 14.2）。
14.4.1 可观察性
这是一个直接的因素 —— 一个不在视野中的角色的可观察性为 0，一个附近且完全可见的角色的可观察性为 1，而可见但遥远的角色的可观察性在中间的某个地方。对于角色，你可以将这个因素计算为与角色占据的屏幕空间（或像素数量）成正比，除以一些 “饱和大小”，指的是角色需要达到多大才能轻松观察到，并且限制为 1：
我们使用距离相机 4 米的完全可见角色占据的屏幕空间作为。对于为高清显示器设计的游戏，较小的饱和值可能更合适。
14.4.2 注意力
如前所述，注意力是最难估计的因素。确定注意力有两个步骤：估计尝试注意力，并应用干扰的效果。
作为第一步，尝试注意力可以计算为可观察性的 EMA：。对于可观察性，你应该调整以实现快速衰减；我们使用，这在 0.1 秒内提供了 95% 的衰减。
你可以将其他因素混合到尝试注意力模型中以提高其准确性。玩家与注意力密切相关的一种行为是聚焦，即玩家试图将角色保持在相机视图的中心。这可以计算为相机前向向量与指向角色的向量的点积的 EMA，然后乘以可观察性。这个项的收敛率应该低得多。其他更特定于游戏的来源也可以用于尝试注意力，例如角色的威胁程度或他的动作速度。然后将加权和用作尝试注意力的估计。对于简单的可观察性和聚焦模型，我们发现权重分别为 0.7 和 0.3，可以很好地预测注意力。
玩家的注意力不是无限的资源；他们需要集中注意力的事情越多，他们对每个事情的注意力就越不集中。一旦计算出所有角色的尝试注意力，你应该将这些因素相加，产生总注意力负载。为了补偿这种干扰效应的非线性（以及来自游戏外部的干扰），你还应该向添加一个恒定的环境注意力负载。每个角色的实际注意力估计是他们的尝试注意力与总注意力负载的比率：，其中。
在游戏中最注意力集中的情况下约占的 1/3。增加它将倾向于将资源偏向背景角色；减少它将倾向于将资源偏向前景角色。
14.4.3 记忆
我们的记忆模型是一个简单的模型，基于对称为联想识别的实验记忆任务的认知模型，以及一种称为回溯干扰的现象。一般来说，玩家对角色的记忆随着时间的推移会趋向于他们当前对该角色的注意力。在记忆（即记忆增加）时，收敛率将是固定的。在遗忘（即记忆减少）时，我们将使用不同的收敛率，其中是总注意力负载。所以它又是一个 EMA，但如果，则，如果，则。我们使用和，这（对于我们观察到的最高注意力负载）导致在大约 5 秒内记忆率达到 95%，在高注意力负载下 10 秒内遗忘率达到 50%。后者往往高估了玩家对角色的长期记忆保留；这对我们来说不是问题，但你可能需要向上调整这个因素。
14.4.4 返回时间
返回时间更客观，因为它估计的是玩家的行为而不是她的想法。它的命名有点误导：输出不是玩家返回的预期秒数，而是玩家返回时当前记忆的预期衰减因子，以及玩家返回的概率。它基于一种称为威布尔危险函数的东西。推导相当复杂，但结果方程是，其中是预期的未来注意力负载（你可以使用当前的注意力负载，或用 EMA 平滑它），是角色上次可见的时间（即，可观察性大于 0）。是一个可调整的参数，你可以通过将观察到的返回时间拟合到威布尔分布来实验确定；我们确定的值约为 0.8，我们认为在其他游戏中这不太可能有太大差异。是上不完全伽马函数。许多流行的数学库，包括 Boost.Math，都包含了这个函数的实现。
14.4.5 持续时间
为了以一个简单易懂的方式完成关键性模型因素，持续时间是专注观察的总时间：在时间上的积分。也就是说，
14.4.6 建模成本
与关键性得分相比，成本的建模更加直接和客观。只需设置你的游戏，让大约一百个角色使用特定的细节等级进行模拟，然后将分析器输出与使用不同细节等级的运行进行比较。
14.5 LOD 和 BIR
再次强调，对 BIR 进行分类的原因是每个类别都可以有自己的关键性得分。有一点脚滑可能不如在墙上原地跑步那么容易被注意到：后者的行为更明显。我们将其称为具有更高的大胆性 —— 也就是说，较低的 LOD 将更加大胆地不真实。但是对于两个角色，如果一个角色脚滑被注意到的可能性是另一个角色的两倍，那么它在原地跑步被注意到的可能性也是另一个角色的两倍。我们不需要为这两种行为分别建立关键性模型，因为相同的因素会影响两者。因此，对于特定类别的 BIR（在这种情况下，不真实状态），每个角色都有一个关键性得分，每个细节等级（在这种情况下，一种可能导致撞墙的本地转向类型）都有一个大胆性得分。综上所述，我们有三个 BIR 类别，每个角色有三个关键性得分，每个细节等级有三个大胆性得分。（请注意，我们现在只关注一个 AI 功能 —— 在这个例子中，本地转向。我们稍后将转向多个功能。）
顺便说一句，上面提到的 “两倍的可能性” 应该让你想起第 14.2.1 节，这并非偶然。对于单个 BIR 类别，我们可以将该类别中细节等级的大胆性得分视为 x 空间中某个 “标准关键角色” 的基本概率，而角色在该类别中的关键性得分则作为其乘数，乘积即为该角色使用该细节等级导致该类别 BIR 的概率。
但它变得更好了！或者，至少，更优雅的数学！由于我们假设独立性，该角色 / 细节等级组合在任何类别中导致 BIR 的概率是所有三个类别的乘积之和。如果我们将所有类别的细节等级的大胆性得分放入一个向量中，称为大胆性向量 A，将角色在所有类别的关键性得分放入另一个向量中，称为关键性向量 C，则组合的总 BIR 概率由点积 A⋅C 给出。线性代数 —— 它不仅仅用于几何了！
14.6 LOD Trader
现在我们有了模型，是时候介绍 LOD Trader 算法本身了。在本文的其余部分，我们将为它添加更多功能；这个初始版本控制单个 LOD 功能（例如，路径查找的执行方式），具有多个可用的细节等级，并限制单个资源（例如，CPU 时间）。
正如你可能从名称中猜到的那样，LOD Trader 基于股票交易者的隐喻。它的 “投资组合” 由所有角色的当前细节等级组成。LOD Trader 的目标是选择一个投资组合，使 BIR 的总概率最小化。当然，最好的投资组合是所有角色都具有最高细节等级的组合；但它还必须将投资组合的总成本限制在其可用资源范围内，所以这（通常）不是一个选项。
每次 LOD Trader 运行时，它都会评估其当前的投资组合，并决定一组交易，将一些角色切换到更高的细节等级，而将其他角色切换到更低的细节等级，因为它们的相对关键性和可用资源发生了变化。请记住，角色在特定细节等级上模拟的总 BIR 概率是角色的关键性向量与细节等级的大胆性向量的点积。因此，LOD Trader 将尝试选择与角色的高关键性得分相对应的低大胆性得分的细节等级。
请注意，对于给定的交易，我们可以找到相对成本，也可以找到相对大胆性，即两个细节等级的大胆性向量的差异。正如特定细节等级的绝对 BIR 概率是角色的关键性向量与细节等级的大胆性向量的点积一样，特定交易的相对 BIR 概率是关键性向量与大胆性变化的点积。我们将 BIR 概率的增加称为升级，将 BIR 概率的降低称为降级。
LOD Trader 用于指导其决策的启发式算法是一种简单的基于价值的算法：真实感改进的单位除以资源成本的单位。如果一个角色以低细节等级进行模拟，将其升级到高细节等级的价值是 BIR 总概率的相对降低除以资源成本的相对增加。有价值的升级将大大降低 BIR 概率并增加低成本。同样，如果一个角色处于高细节等级，将其降级到较低细节等级的价值是 BIR 总概率的相对增加除以成本的相对降低；有价值的降级将只会略微增加 BIR 概率并大大降低成本。为了使数学简单，我们将加入一个负号，因此升级值为正，并且更有价值的升级具有更大的幅值。对于降级，值也为正，但最有价值的降级将具有较小的幅值。（例外情况应特别处理。在某些情况下，细节升级将导致成本降低，或者细节降级可能导致成本增加。前者应始终被选择；后者永远不应被选择。）
在一次运行中，LOD Trader 运行一个或多个迭代。在每次迭代中，它假设进行一组交易（包括升级和降级），这些交易将尊重资源限制并可能导致 BIR 概率的总体降低。如果假设的交易集实际上确实降低了 BIR 概率，则实际执行这些交易，并且交易者继续迭代，以尝试找到其他交易。一旦它找到一个假设的交易集，该交易集不会降低 BIR 概率，它就会停止（并且不会进行这些交易）。
选择假设交易集的算法很简单。首先它考虑升级。它反复选择最有价值的可用升级添加到其交易集中，直到超出其资源预算。然后，它反复选择最有价值的可用降级添加到其交易集中，直到没有超出其资源预算。升级和降级存储在优先级队列中，以降低搜索成本。LOD Trader 的伪代码如清单 14.1 所示；请记住，这是初始版本，我们将添加更多功能并提高性能。
14.6.1 多个功能
多类别关键性建模的最有用的效果之一是能够同时控制不同类型的 LOD。例如，我们可以控制路径查找质量（其质量主要影响 ULTB BIR 的概率）和手部 IK（这影响 US BIR 的概率）。换句话说，我们想要控制多个功能（其细节是根据每个角色设置的 AI 系统）。当然，我们可以通过运行多个 LOD Trader 来实现，每个功能一个。但是那样我们就必须为每个功能分配一个单独的预算；当一个或另一个变得重要时，就没有办法自动在路径查找和 IK 之间转移资源，也无法将一个角色的路径查找质量降级与另一个角色的 IK 质量升级进行交换。
多交易者方法的另一个问题是某些功能可能相互依赖。例如，我们可能同时控制角色的基本行为（目标驱动或只是站在周围）和他的路径查找（高质量、低质量或禁用）。当然，目标驱动行为和禁用的路径查找作为细节等级是不兼容的，但没有有效的方法来协调两个交易者以避免这种结果。
相反，我们让一个单独的 LOD Trader 同时平衡所有功能的细节等级。LOD Trader 看到的角色的当前 “状态” 将不是单个细节等级，而是他们所有功能的当前细节等级的组合。我们将所有功能的级别集合称为功能解决方案，该集合尊重所有功能间的约束。我们不是选择单个功能转换，而是选择从一个功能解决方案到另一个功能解决方案的功能解决方案转换，每个转换可能导致多个功能转换。对于每个功能解决方案，我们将预先计算并存储可能的升级转换和可能的降级转换的列表，以便我们知道对于当前处于任何特定功能解决方案的角色要查看哪些转换。
如果功能集很小，这对算法几乎没有影响；唯一的主要变化是需要检查我们是否不为单个角色选择多个升级或降级转换。然而，功能解决方案的数量随着功能的数量呈指数增长。由于我们必须评估每个角色 / 功能解决方案组合并将其插入我们的优先级队列中，这可能导致大量的计算和大量的内存使用。大部分工作将被浪费，因为它将用于评估许多遥远、不重要角色的昂贵升级 —— 考虑到它们微小的关键性向量，我们应该知道我们不会以任何方式升级这些角色。
14.6.2 扩展队列
相反，我们将使用一种新的、更懒惰的策略。我们将从一个角色的优先级队列开始，而不是升级转换的优先级队列；我们将其称为扩展队列。我们将用于扩展队列的排序键是扩展启发式算法，它估计该角色的任何转换可能达到的最佳值。这个值代表每个角色的转换值的上限，可能是过度乐观的，但它永远不会是悲观的；从这个意义上说，它类似于 A * 搜索的可接受启发式算法。我们将通过 “扩展” 队列前面的角色（具有最高扩展启发式算法的角色）到其所有可能的升级转换，并选择最有价值的转换来选择升级转换。扩展角色的伪代码如清单 14.2 所示。
由于启发式算法可能过于乐观，我们不能保证扩展队列前面的角色实际上具有所有角色中最有价值的升级转换。为了补偿这一点，即使我们已经超出了资源预算，我们也将继续扩展角色。一旦我们超出预算，每次我们扩展一个角色并为我们的假设交易集选择一个新的升级时，我们将反复删除并丢弃升级中价值最低的交易，直到我们只超出一个交易（也就是说，删除另一个价值最低的交易将使我们低于预算）。为了使这一过程高效，我们将选择的假设升级集本身存储为一个优先级队列，其顺序使得前面的元素具有最低的值。通常，刚刚扩展、刚刚插入的升级本身就是价值最低的交易，并且在添加后立即被删除。
我们什么时候可以停止这样做？当已经选择的最差值转换 —— 假设升级队列前面的转换 —— 具有比扩展队列前面的启发式预测值更高的值时。由于启发式算法的可接受性，我们知道此时我们永远不会找到比我们已经选择的更好的升级，所以我们可以停止而无需扩展任何更多的角色，并且选择的升级集是假设升级队列中剩余的升级。在实践中，这很快就会发生。
降级阶段的工作方式类似：我们保持一个按最小可能值排序的扩展队列，并为每个扩展角色选择最低值的降级，将其插入我们的假设降级队列中。一旦我们的资源约束不再被违反，在每次选择后，我们继续从假设降级队列中弹出最大值的降级，直到弹出下一个降级会违反资源约束。一旦扩展队列前面的角色的启发式值大于假设降级队列前面的降级值，我们就停止扩展角色。
14.6.3 修剪转换
在我们达到最佳可能值启发式算法之前，让我们看看某一类功能解决方案转换。这些转换可以被称为 “小气而粗心”。或者，也许从技术上讲，它们可以被称为愚蠢。例如，一个功能转换将动画 IK 升级到最高质量，但保持碰撞避免关闭，这将是愚蠢的。它是被允许的，是的，但它永远不应该被选择；在你决定在高质量 IK 上花费 CPU 时间之前，你应该首先决定让角色不穿过墙壁。愚蠢转换的可能性对 LOD Trader 来说不是问题，因为它永远不会选择它们，但它确实会花费时间来评估它们。事实证明，很多解决方案转换 —— 在我们的经验中，超过一半 —— 都是愚蠢的。
愚蠢转换的特征是什么？从数学意义上讲，它被其他转换 “严格支配”；也就是说，无论情况如何，总有一个更有价值的转换。让我们来研究一下如何识别它们，以便我们可以忽略它们。
请记住，（对于升级）的值是概率收益 —— 关键性和大胆性的点积除以相对成本增加。为了将其表示为方程形式，对于将角色从功能解决方案切换到功能解决方案，我们将资源成本的变化称为，大胆性的变化称为，结果值称为。（记住负号 —— 我们希望升级的值为正，尽管更高的质量意味着更低的大胆性。）这取决于关键性向量。如果对于任何可能的关键性向量，都存在一些其他更好的功能解决方案，使得，则从到的转换是 “愚蠢的”。
对于给定的功能转换，确定它是否被严格支配可以表述为一个线性规划问题。或者，你可以生成大量随机的关键性向量，并为每个向量找到最佳转换。任何至少一次未被选择的转换都被假定为被严格支配，并从在该起始功能解决方案中评估的升级列表中删除。对于愚蠢的降级，同样的事情也会发生，但 “最佳” 转换是具有最小幅值的值的转换。
14.6.4 扩展启发式算法
回到启发式算法，我们将用它来处理扩展队列 —— 也就是说，估计每个角色的任何转换的最佳可能值。让我们再次看看这个值公式：。重新排列后，它是，其中。对于特定的起始功能解决方案，我们可以将所有升级转换的向量收集到一个矩阵中。然后我们可以修剪它，删除任何列，该列没有至少一个条目大于不同列中的相应条目。一旦我们为每个起始功能解决方案存储了矩阵，我们就可以非常快速地计算启发式值，作为向量中的最大条目。我们对降级转换做同样的事情，使用一个单独的矩阵。（请记住，对于降级，我们希望较小的值，所以我们修剪没有至少一个较低条目的列。）这个值启发式计算在清单 14.3 的伪代码中显示。
14.6.5 多种资源
CPU 时间可能不是我们唯一的资源约束。例如，假设我们想要控制的一个功能是角色是否记得对他友好或敌对的其他角色。这很容易成为一个大的 RAM 消耗，所以我们也希望将我们的内存使用保持在特定的预算之下。在这种情况下，我们可能能够使用多个 LOD Trader，每个资源类型一个，但可能单个功能可能对多个资源产生影响。像以前一样，我们希望一个交易者来完成平衡所有事情的工作。细节等级的成本现在将是向量值，功能解决方案的总成本和功能解决方案转换的相对成本也将是向量值。
我们首先要做的是调整我们的价值启发式算法。“除以成本” 不再起作用，因为成本是一个向量。我们将使用资源乘数向量来生成成本的标量度量。在升级阶段，每个资源类型的资源乘数是该资源当前未使用量的倒数。如果 CPU 时间很宝贵但有大量的空闲内存，资源乘数向量将为 CPU 提供比 RAM 更大的条目。如果资源既没有超支也没有未充分使用，它应该有一个大但不是无限的资源乘数。在降级阶段，资源乘数与超支量成正比；未超支的资源的资源乘数为 0。资源乘数向量在每次升级和每次降级阶段之前重新计算，但在升级或降级阶段期间不计算。
接下来，我们需要调整我们的停止标准。我们将选择升级，直到任何资源超支，而不是选择升级，直到只有一个资源超支。然后，我们将选择降级，直到没有资源超支。
我们还需要调整我们对愚蠢功能解决方案的定义，以及我们的扩展启发式算法。当确定一个功能解决方案是否会被选择时，我们不仅需要检查大量随机的关键性向量，还需要检查资源乘数向量。当生成时，我们需要在所有可能的资源乘数向量上最大化它：。（对于这两者，你应该只考虑归一化的资源乘数。）为了从功能解决方案修剪和扩展启发式算法中获得最佳性能结果，你应该得出资源乘数之间比率的预期限制，并将实际资源乘数剪辑到这些限制。
最后，请注意，一些功能解决方案转换将具有正负资源成本：这些应该被允许作为升级，但不允许作为降级。
14.6.6 整合在一起
清单 14.5 显示了支持多个功能和资源类型的更新后的伪代码。
14.6.7 LOD Trader 的其他扩展
除了限制不同功能的不同等级可以一起使用之外，还可以限制单个功能的哪些等级可以转换到其他哪些功能。例如，你可能将角色从预录制动画转换为完全动态运动，但不能从动态运动转换回预录制动画。这可以通过丢弃包含此类转换的功能解决方案转换来简单地完成。
还可以将成本和大胆性附加到功能转换本身，而不仅仅是功能级别。如果转换过程本身需要大量计算，将成本附加到转换上可能很有用；如果转换可能导致可见的 “弹出” 或涉及角色信息的丢失，从而可能导致 FD 或 ULTB BIR，将大胆性附加到转换上可能很有用。
在某些情况下，为特定的 LOD 功能引入 “空” 细节等级的概念是有用的。例如，“站在周围” 行为细节等级将仅与 “空” 移动细节等级兼容，而 “做事情” 行为细节等级将与除空等级之外的所有移动细节等级兼容。
LOD Trader 的一个不寻常但有用的应用是作为通常用于删除远处角色的 “模拟气泡” 的替代方案。这是通过 “存在” LOD 功能来完成的，具有 “是” 和 “否” 级别，其中 “否” 级别与所有其他 LOD 功能的 “空” 级别兼容，具有零大胆性和零成本，但从 “是” 到 “否” 的转换本身具有 US 和 FD 大胆性。当一个角色转换到 “否” 存在级别时，它将被删除。
另一个不寻常但有用的应用是将 “节省空间” 视为额外的资源。这只能在游戏即将保存时进行约束，并确保在保存到空间有限的设备时保留游戏状态中最有用和最难忘的部分。
LOD Trader 也可以在多人游戏中使用，只需根据当前观察该角色的所有玩家的关键性总和来计算给定角色的关键性。由于 x 空间概率的加性性质，这将导致正确估计和最小化 BIR 概率。此外，LOD Trader 可用于通过控制不同角色的更新率和更新细节来分配网络带宽；在这种情况下，为每个玩家运行一个单独的 LOD Trader 实例。
最后，并非 LOD Trader 控制的所有角色都需要具有相同的 LOD 功能；你只需要为每个 “类型” 的角色维护不同的转换集，然后让 LOD Trader 控制，比如说，行人和固定店主。实际上，并非 LOD Trader 控制的所有 “角色” 都必须是角色：它可以异构地管理人类、车辆、可破坏物体以及任何可以从关键性驱动的 LOD 控制中受益的事物。
14.7 LOD Trader 的实际应用
我们在 LOD Trader 的应用中取得了很好的效果。我们在一个涉及数百个角色的自由漫游游戏中实现了它，让它控制八个单独的功能，具有数百个潜在的功能解决方案。我们还实现了传统的基于距离的 LOD 选择，以便我们可以进行比较。LOD Trader 实现过程中最棘手的部分是调整关键性指标和大胆性向量，因为它们的主观性。在这方面，游戏测试者的反馈可能非常有帮助。
正如预期的那样，基于距离的 LOD 选择只是勉强可以接受。为了保证合理的帧率，有必要将阈值距离设置得如此之近，以至于低质量的移动等问题可以清晰地看到，特别是在游戏世界中人口稀少的区域和视线不受阻碍的长距离区域。相比之下，LOD Trader 在最拥挤的情况下非常有效地维持了帧率，并且在稀疏区域，它以最高 LOD 模拟了大多数角色。
一项受控的、盲目的实验研究证实了我们的印象：观看使用基于距离的 LOD 选择运行游戏的视频的观众比观看使用 LOD Trader 运行游戏的视频的观众更有可能体验到 BIR，并且更频繁地体验到 BIR [Sunshine - Hill 11]。
LOD Trader 本身具有非常好的性能：其平均执行时间为每帧 57 微秒，或目标帧时间的 0.17%。其内存使用为转换数据 500 kB，每个实体 48 字节，通过选择更窄的数据类型，这两者都可以轻松减半，而功能不受影响。
14.8 结论
如引言中所述，LOD Trader 并不神奇。它不能读懂玩家的心思。它的关键性模型是近似的，而且往往非常不准确。
但这没关系。LOD Trader 的目标不是进行大胆的细节减少并侥幸逃脱。相反，它的目标是足够聪明，在必须进行细节减少的时刻，在正确的地方进行细节减少。在这些时刻，问题不是是否减少 LOD，而是如何在不引起明显问题的情况下减少 LOD，而我们不能依赖基于距离的 LOD 选择来做到这一点。
我们需要能够依赖我们的 LOD 选择器。因为细节减少总是、总是需要的。我们永远不会有足够的计算资源来做我们想做的所有事情。当我们在运行时不进行细节减少时，这只意味着我们在开发时进行了细节减少，因为我们不知道我们是否总是能够负担得起这些好的技术而放弃了它们。这就是 LOD Trader 的真正好处：能够实施我们所能想象的最详细的 AI 技术，以及我们所能设计的最具可扩展性的技术，并相信我们的游戏能够在最重要的时候利用每一项技术。