二杠二、结构架构 —— 常见技巧
凯文・迪尔
5.1 引言
在讨论游戏人工智能时，开发者往往过于专注于倡导特定的方法或特定的架构，但许多使人工智能编程如此困难的问题无论使用何种架构都会出现，许多最常见的解决方案在一个又一个架构中被反复重新发明。例如，我们可以使用层次结构来划分人工智能逻辑，简化配置和执行。我们可以使用选项栈来允许一个选项暂时暂停另一个选项，而不改变总体攻击计划。我们可以使用黑板在人工智能组件之间或角色之间共享信息和想法。我们可以将智能移动到对象、地形、能力或事件中，以便更逻辑地划分代码和数据，并提高我们扩展游戏的能力。（一些游戏，如《模拟人生》系列，使用这种方法发布可下载内容甚至整个扩展包，而无需更改可执行文件。）最后，我们可以使用模块化来提取可重用的人工智能逻辑片段，从而同时消除重复代码并使人工智能的作者能够在更粗粒度的级别上思考。
在本章的其余部分，我们将描述这些想法中的每一个。目的是提供足够的信息来描绘大局，激发读者可能面临的问题的新想法和解决方案，但不深入探讨任何给定解决方案的技术细节。为此，我们请您参考参考书目和其中包含的参考文献。
5.2 定义
本文中我们将要解决的想法是相当普遍的，但不一定有通用的术语来描述它们 —— 在某些情况下，术语对一个人意味着一件事，对另一个人意味着另一件事。因此，本节将定义可能不清楚的术语，以便我们在前进时有一个共同的词汇表可以使用。
人工智能架构是底层代码 —— 通常用 C++ 编写，它控制人工智能评估情况并做出决策的过程。下面将给出几个架构的例子，本节中的其他文章将详细描述其中的许多架构。
配置是从特定感官数据（即特定输入）到特定决策或行动（即特定输出）的行为规范。例如，第一人称射击游戏（FPS）角色的配置将包含决定该角色在游戏中的每个点应该做什么的所有逻辑 —— 例如，它应该攻击、逃跑、重新装填武器等等。配置建立在架构之上，通常在数据中指定（即 XML 或类似格式）。
我们经常将人工智能控制的东西称为角色。并非所有的人工智能都控制单个角色 —— 例如，您可能正在为策略游戏中的对立玩家的人工智能工作（它控制许多角色），或者为飞行游戏中的导弹的人工智能工作，甚至是控制用户界面某些方面的人工智能。您还会听到人工智能控制的实体被称为智能体、敌人或简单地称为人工智能。然而，通用术语角色是一个方便的术语，并且大多数人工智能确实适用于角色，因此我们在本章中将坚持使用它。
通常情况下，一个角色会包含多个决策者。例如，一个角色可能有一个算法选择使用哪种武器，另一个算法选择射击的目标，第三个算法决定它应该显示什么情绪。我们将这些决策者称为推理器。推理器可能有明确的责任（如上述描述），也可能以更特别的方式组织（如行为树中的选择器 ）。
同样，我们将推理器选择的东西称为选项。推理器通过首先评估情况，然后选择一个或多个选项来执行来发挥作用。当推理器选择一个新选项并开始执行它时，我们说它选择了该选项，当它停止执行一个选项时，我们说该选项被取消选择。这些选项可能是行动（即人工智能所做的物理事情），但它们也可能更抽象。例如，角色的情感推理器可能只是改变人工智能的内部状态（也许通过将枚举值设置为适当的状态 ——eHappy、eSad、eAngry 等 —— 或通过为每个情感分配一个强度值），以便其他推理器可以根据该状态选择适当的行动（微笑、皱眉、攻击玩家等）。
5.3 常见架构
尽管这里描述的技术旨在与架构无关，但在描述它们时讨论特定的架构通常是有用的。所有这些架构都在其他地方有详细的描述，所以我们只对每个架构进行非常高层次的定义。
脚本可能是最基本的架构。在其中，设计师或人工智能程序员指定人工智能将选择的选项序列以及它们将被选择的时间（例如，等待 48 秒，然后生成三个单位并攻击玩家）。脚本可能包括非常简单的感官输入，如触发区域，但总的来说，想法是人工智能的每个决策都由其作者完全指定。
有限状态机（FSM）曾经是最流行的游戏人工智能架构，但近年来已在很大程度上被行为树所取代。FSM 是状态和转换的集合。状态代表推理器可以选择的选项，而转换代表人工智能将从一个状态转换到另一个状态的条件。例如，一个非常简单的第一人称射击游戏（FPS）角色可能有四个状态：攻击、逃跑、重新装填和寻找敌人。攻击状态将包含转换到逃跑（如果角色几乎死亡则触发）、重新装填（如果角色没有弹药则触发）和寻找敌人（如果角色失去敌人的视线则触发）。
基于规则的人工智能由一系列谓词 - 选项对组成。人工智能按顺序评估每个规则的谓词。当它到达一个谓词为真的规则时，它执行该规则的选项并停止评估其他规则。因此，我们简单的 FPS 角色的基于规则的人工智能将有四条规则。第一条规则是如果其健康值低，则使其逃跑。第二条规则是如果它没有弹药，则使其重新装填。第三条规则是如果玩家在视线内，则使其攻击玩家。最后，第四条规则是寻找玩家。
基于效用的人工智能使用启发式函数为每个选项分配一个浮点值（通常称为权重、优先级或效用）。然后，它根据这些值选择要执行的选项 —— 例如，通过选择效用最高的选项，或为每个选项分配一个权重，并使用该权重来指导随机选择的概率。我们简单的 FPS 角色仍然有相同的四个可能选项，但现在它将通过评估每个选项的启发式函数并使用结果值来指导其最终选择来决定做哪个选项。
规划器，如面向目标的行动规划器（GOAP）或分层任务网络（HTN）规划器，构建一个选项序列，使它们达到某个目标状态。例如，我们的 FPS 角色可能有目标 Enemy Dead。它将搜索其可能的选项以及它们改变世界状态的方式，以找到一个将其带入目标状态的选项序列。该计划可能类似于 Search for Enemy - Attack - Reload - Attack（如果它预计两个弹匣的弹药足以完成工作）。规划器通常具有在情况发生变化时重新规划的能力。因此，如果我们的角色发现自己几乎死亡，那么它可能会以新的目标重新规划，例如 Don't Die。这个新计划可能只有一个选项：逃跑 。
行为树（BT）架构有点特殊，因为它是一种可以包含其他架构的架构。BT 是一个选择器的树，每个选择器都做出整体决策的一小部分。在它们的原始公式中 ，选择器都非常简单，本身并不是真正的架构。然而，最近的工作讨论了在选择器中使用几乎任何架构的能力，使行为树更像是一个框架（或元架构），而不是本身的架构。
5.4 分层推理
构建人工智能配置的难度通常与配置的大小不成线性比例。换句话说，人工智能能够处理的情况越多，它考虑的因素越多，它包含的选项越多，等等，添加其中任何一项的另一个因素就越复杂。这一原因应该是相当直观的。每当您向人工智能添加新内容时，您至少需要付出一些努力来考虑这个新事物如何与已存在的每个事物相互作用。因此，添加新事物的成本会随着您拥有的事物的增加而增加。
这种增加的严重程度在很大程度上取决于您使用的架构。例如，FSM 的规模呈指数增长，因为转换的数量与状态的数量呈指数关系。这很快就会变得无法管理。这是 FSM 在复杂问题中基本上不再使用的主要原因之一。另一方面，基于效用的人工智能只需要您适当地平衡启发式函数，而基于规则的人工智能通常只需要您将新规则放在列表中的适当位置。话虽如此，即使是基于规则的人工智能，当它包含数百或数千条规则时（对于许多游戏来说，这并不是一个不合理的大小），也会变得脆弱。
解决这一挑战的一种常见方法 —— 一种已应用于游戏和学术界几乎所有架构的方法 —— 是分层分解决策。也就是说，有一个高级推理器做出重大的、总体的决策，然后有一个或多个低级推理器来处理高级推理器决策的实施。例如，高级推理器可能决定是执行日常环境任务的时间表（例如，起床、吃早餐、上班等），与玩家开始对话，进入战斗等等。每个选项都将包含另一个推理器，该推理器决定如何实现该目标。
这里的优势是，人工智能配置的复杂性与特定推理器中选项的数量不成线性比例。为了了解其相关性，想象一下配置人工智能的成本是 O (n^2)，与选项的数量有关（就像 FSM 一样）。如果我们有 25 个选项，那么配置人工智能的成本大约是 25^2 = 625。另一方面，如果我们有五个推理器，每个推理器有五个选项，那么配置人工智能的成本只有 5×(5^2) = 125。从概念上讲，这是有道理的。当我们添加一个新选项时，我们只需要考虑它与同一推理器内的其他选项的关系 —— 这比将它与人工智能中任何其他地方的每个其他选项进行比较要简单得多。
这种方法的例子比比皆是，从分层 FSM到 HTN 规划器和 GOAP 实现，再到将对立玩家人工智能分解为命令层次结构的策略游戏人工智能。行为树也许是典型的例子 ——BT 实际上只不过是一个分层基础设施，您可以在其中放置最能封装要做出的决策的任何推理架构。
5.5 选项栈
大多数反应式人工智能通过非常频繁地评估情况（通常每帧）并决定在那个特定时刻做最好的事情来发挥作用。它们可能有过去决策的历史来指导它们的选择，它们甚至可能有一些更大的计划，但决策是逐刻做出的。这就是为什么如果情况发生变化，人工智能能够做出响应。
当然，我们确实希望选项是持久的。也就是说，我们不希望人工智能在不同的决策之间不断摇摆 —— 一帧攻击，下一帧逃跑，然后再下一帧又攻击。或者，例如，用霰弹枪攻击，然后用火焰喷射器攻击，然后在一两帧后又回到霰弹枪，切换武器太快甚至无法开枪。这种犹豫不决会让人工智能看起来很愚蠢，即使当时做出决策有很好的理由。正如我们在前面的章节中讨论的，看起来愚蠢是人工智能能做的最糟糕的事情。它打破了玩家的沉浸感 —— 即他们对体验的沉浸。因此，大多数架构都内置了某种形式的惯性，除非有充分的理由改变，否则人工智能会继续做同样的事情。
当人工智能确实改变选项时，会出现两种可能的情况之一。在大多数情况下，人工智能的决策是持久的 —— 也就是说，它已经决定停止旧选项并开始一个新选项，并且它不期望回到之前正在做的事情。例如，如果人工智能在战斗中杀死了一个敌人，现在它可以选择一个新的敌人来攻击（或者如果战斗结束，则选择做其他事情）。决策可以是持久的，即使人工智能没有完成之前的选项。例如，当人工智能决定逃跑时，这是一个持久的决策，即使它通常发生在人工智能完成攻击之前。无论如何，人工智能已经做出了停止正在做的事情并转而做其他事情的故意决定。在这种情况下，我们应该停止对取消选择的选项应用惯性，实际上甚至可能想要应用一个冷却时间，这将阻止我们在短时间内回到它。
然而，有些情况下，人工智能需要对即时的需求或机会做出反应，但一旦反应完成，它应该回到之前的选项。例如，如果人工智能需要重新装填，它应该在重新装填完成后回到相同的行动（大概是发射特定的武器）。重新装填霰弹枪后立即切换武器到火焰喷射器（或决定逃跑）是没有意义的。这并不是说人工智能不能改变主意，但它必须克服该选项的惯性才能这样做，就好像该选项仍在执行一样。因此，我们可能会在重新装填霰弹枪后立即切换到火焰喷射器 —— 但只有当我们突然发现一些新的敌人对火非常脆弱时。
一种应用于许多架构的常见技巧是拥有一个当前执行选项的栈。这个栈有时被称为状态栈，或目标栈，或包含，具体取决于底层架构，但我们将其简单地称为选项栈，因为这是一个与架构无关的术语。选项栈允许我们将一个新的、高优先级的选项推到栈顶，暂停当前执行的选项，但保留其内部状态。当高优先级选项完成执行时，它将自己从栈中弹出，之前执行的选项将恢复，就好像什么都没发生过一样。
选项栈有无数的用途，它们通常可以有好几层深。例如，一个高级战略推理器可能决定派遣一个单位去攻击远处的敌人前哨。在途中，该单位可能会遭到伏击 —— 在这种情况下，它可能会将 React to Ambush 选项推到其选项栈的顶部。在响应伏击时，该单位中的一个角色可能会注意到一颗实弹手榴弹刚刚被扔到它的脚下。该角色可能会将 Avoid Grenade 选项推到 React to Ambush 选项的顶部。一旦手榴弹爆炸（假设角色还活着），它可以将 Avoid Grenade 选项从栈中弹出，React to Ambush 选项将恢复。一旦敌人的伏击结束，它也会被弹出，原始的 Attack 选项将恢复。
一个方便的技巧是使用选项栈来处理你的命中反应。如果一个角色被敌人的攻击击中（例如，一颗子弹），我们通常希望他们表现出明显的反应。我们也希望角色在反应时停止它正在做的任何事情。例如，如果一个敌人在我们击中它时正在开火，它在命中反应播放时不应开火。如果它这样做，看起来就不对了。因此，我们将一个 Is Hit 选项推到选项栈上，在反应播放时暂停所有先前运行的选项，然后在反应完成时将其弹出。
我们上面提到过，但值得再次强调的是，选项栈并不是为了阻止人工智能改变它正在做的事情，而只是为了保存它之前的状态，以便在决策中适当考虑。为了扩展前面的例子，想象一下角色的手臂被击中，结果失去了使用该手臂的能力 —— 因此无法再发射武器。在这种情况下，它当然应该选择一个不同的选项。选项栈只是确保人工智能拥有之前行动的上下文，以便它能够做出明智的决策。
对于大多数架构来说，选项栈的实现非常简单。在人工智能配置中，每个选项都可以指定它是否应该暂停前一个选项（即，将新选项推到栈上）或取消选择它（即，这是一个持久的决策）。当一个暂停其前身的选项完成执行时，它会自动弹出栈并恢复之前的选项。有一些边缘情况需要处理（例如，如果在栈上有选项时选择了另一个选项该怎么办？），但它们并不难管理。支持此功能的接口的示例可以在我们的 GAIA 架构中找到。
5.6 知识管理
知识是做出良好决策的关键。这在现实世界中是正确的，在游戏人工智能领域更是如此，在游戏人工智能领域，大多数决策都归结为对当前情况的相对简单的检查。当然，这句话中隐含着两种不同的知识 —— 对情况本身的知识，以及如何评估情况以做出决策的知识。从这个角度来看，人工智能除了知识之外没有太多东西。
鉴于知识在游戏人工智能中的核心作用，值得努力思考如何最好地存储和访问我们的知识。
5.6.1 黑板
在学术人工智能社区中，黑板架构通常指的是一种特定的方法，其中多个推理器提出问题的潜在解决方案（或部分解决方案），然后在黑板上共享该信息。然而，在游戏社区中，该术语通常仅用于指各种人工智能组件可以用来存储可能对多个组件有用或可能需要多次使用的知识的共享内存空间。例如，在我们的架构中，每个角色都可以访问两个黑板。角色黑板存储特定于角色的信息，并且只能由该角色的人工智能访问。全局黑板可由所有角色访问，并用于存储一般信息。
黑板上可以存储许多类型的信息。一种常见的用途是在黑板上存储昂贵的检查，以避免多次运行它们的成本。视线（LOS）检查是一个常见的例子。通常，人工智能中的多个组件（或多个角色的人工智能）都希望检查相同两个对象之间的可见性。这些检查可能非常昂贵。为了减轻这个问题的影响，我们可以运行一次检查，然后将其缓存在黑板上。路径规划检查类似。
另一种常见的用途是存储用于协调人工智能组件的信息。这可能包括经典黑板系统中发现的部分解决方案，但也可能只是用于在多个角色之间或角色内的不同人工智能组件之间进行协调的信息。例如，如果您希望您的角色将攻击集中在一个敌人身上，或者确保每个敌人都受到攻击，您可以在黑板上存储目标分配。如果您想协调空间运动 —— 也许是侧翼，或者将坦克放在前面，将 DPS 和治疗者放在后面，那么您可以在黑板上存储运动计划。如果您想确保两个角色不会尝试使用同一个掩护点，那么您可以让它们在黑板上预订。如果您有一个推理器，其输出是另一个推理器的输入 —— 例如，我们在本文前面讨论的情感推理器 —— 那么该输出可以放在黑板上。
在AIGameDev.com上有对达米安・伊斯拉（Damián Isla）的采访，它很好地介绍了黑板架构在游戏中通常的使用方式。
5.6.2 智能万物
当我们考虑一个角色的人工智能时，将所有所需的知识放在角色中似乎是直观的。然而，这可能导致一个庞大、难以扩展的人工智能，也可能导致类似（但不完全相同）角色之间的大量重复。
一个技巧是将智能放在世界中，而不是角色中。这种技术由《模拟人生》推广开来，尽管更早的例子也存在。在《模拟人生》（及其续作）中，世界中的物体不仅宣传它们提供的好处（例如，电视可能宣传它具有娱乐性，床可能宣传你可以在那里休息），它们还包含有关如何执行相关行动的信息。
这种方法的另一个优点是它大大降低了扩展包的成本。例如，在《动物园大亨 2》系列中，每隔一个扩展包都是 “仅内容”。因为大部分智能都构建在物体中，我们可以创建新的物体，这些物体可以被现有的动物使用，甚至可以创建全新的动物，而无需对源代码进行任何更改。这大大降低了开发这些扩展的成本，使我们能够将精力集中在更大的扩展上，每年推出两个扩展，而不是仅仅一个。
智能也可以放在世界本身中。例如，在《荒野大镖客：救赎》中，居住在城镇中的人们本身几乎没有智能 —— 但城镇有数百个热点。每个热点都包含有关谁可以使用它、热点在一天中的什么时间有效以及在该热点上的角色的行为树的信息。一些热点甚至可能需要多个角色。因此，例如，酒馆中的椅子可能有一个用于坐着喝酒的热点和另一个用于玩扑克的热点 —— 但后者只有在桌子上有四个人时才有效（并且包括协调他们行动的机制）。钢琴凳有一个只有钢琴演奏者才能使用的热点，酒吧有多个调酒师的热点（一些需要其他角色加入，一些不需要）。甚至对话人工智能也通过为将要进行对话的两个角色创建一个动态热点来工作。
当然，智能可以放在任何地方，不仅仅是在物理对象或位置上。例如，具有广泛特殊能力的游戏可以将智能放入这些能力中。《暗黑孢子》是一款拥有数百种能力的游戏 —— 其中许多非常独特 —— 采用了这种方法。同样，事件可以携带有关适当响应的信息。例如，学校的火灾可以携带有关不同类别的人（例如，教师、儿童、消防员、家长等）应该如何反应的信息。
5.7 模块化
角色的组件系统在游戏社区中已经变得司空见惯。例如，一个角色可能有一个运动组件、一个动画组件、一个人工智能组件、一个武器组件等等。每个组件都通过一个共享接口封装了角色功能的一个方面。这种模块化 —— 将一大段代码分解为具有一致接口的小而可重用的部分 —— 可以非常强大。它可以让我们大大减少代码重复，并在项目内部和跨项目中更多地重用我们的代码。此外，我们可以更快地实现我们的角色，因为我们只需要插入适当的模块，而不是在代码中重新实现功能。能够在广泛的概念级别（即整个模块）上思考，而不是专注于单个代码行，这是非常解放的。
模块的一个非常强大的用途是创建考虑因素，这些模块可以组合起来评估一个选项的有效性。回到我们简单的 FPS 角色，重新装填选项只有一个考虑因素，它检查当前武器中剩余的弹药量。另一方面，逃跑选项可能有考虑因素来评估当前的健康状况、剩余盟友的数量、敌人剩余的健康状况、可用的武器等等。人工智能会将这些考虑因素的输出组合成一个最终评估，根据当前情况，逃跑的重要性如何。这些考虑因素集的输出可能是布尔值（例如，用于驱动基于规则的推理器或 FSM 中的转换），也可能是连续的（例如，用于驱动基于效用的人工智能）。考虑因素的最大优点是，那些完全相同的考虑因素可以用于其他决策 —— 例如，是否积极攻击，是否使用健康包等等。更重要的是，考虑因素本身可以在项目之间重用。即使是非常不同的游戏（例如，实时战略游戏或角色扮演游戏）可能也需要健康检查、幸存盟友的数量、距离检查等等。此外，许多元概念，如选项惯性和冷却时间（在前面的部分中描述），可以很容易地表示为考虑因素。
一旦你接受了模块化，你会发现它可以应用到你的整个代码库中。例如，我们经常有一个需要目标的行动。目标可以是特定的角色（也许是玩家）、相机、特定的 (x, y, z) 位置。它甚至可以是另一个推理器的输出 —— 也许是一个评估所有敌人并选择最佳攻击目标的推理器。通过拥有一个模块化的目标类，我们可以将指定和更新目标的逻辑与使用它的行动解耦。此外，目标也可以在其他地方使用，例如在考虑因素中 —— 例如，一个距离考虑因素可能会测量两个目标之间的距离，而不知道或不关心它们是什么类型的目标。目标甚至可以存储在黑板上，允许角色之间进行通信（如前面部分所述）。
模块化的另一个例子是权重函数。当我们使用考虑因素来驱动基于效用的人工智能时，我们发现有很多考虑因素需要从浮点值（如距离、剩余健康量、剩余弹药量、剩余敌人数量、自某个行动以来的时间、角色当前的饥饿度、卫生间需求、对玩家的看法等）映射到效用值。尽管可能有数十个甚至数百个这样的考虑因素，但实际上只有几种方法来处理从输入值（即考虑因素计算的值）到返回值（即考虑因素的输出）的映射。例如，我们可以直接返回输入值，对输入值应用数学函数并返回结果，或者将输入值划分为范围，并为每个范围返回特定的输出值。权重函数是使用这三种技术之一为我们进行映射的模块化组件。它们允许我们将映射与考虑因素解耦，确保我们对每种映射类型都有一致的数据规范，并使我们能够将大量重复的代码，其中一些相当复杂，移动到几个相对简单的类中。此外，它们允许我们以一致的、经过良好测试的方式添加高级功能，如滞后。
这些只是人工智能概念可以抽象为可重用模块的许多方式中的几个。关于模块化广泛使用的其他想法可以在我们之前的论文中找到。我们的经验是，找到以可重用、可插拔模块（而不是 C++ 代码）的方式思考我们的人工智能的方法，可以极大地提高生产力，即使在节奏非常快的项目中也是如此。
5.8 结论
在本文中，我们讨论了许多在许多人工智能架构中使用的常见技术，这些技术可以促进您的游戏的创建。层次结构可用于将决策划分为合理大小的部分，极大地简化了配置过程。选项栈可以使人工智能对临时情况或机会做出响应，然后回到它之前正在做的事情。知识可以在黑板上共享，或放在对象、地形、行动或事件中。最后，在实现人工智能时可以使用模块化来消除大量重复代码，并使您在执行配置时能够从广泛的概念而不是单个代码行的角度进行思考。