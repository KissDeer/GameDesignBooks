一杠一、游戏人工智能是什么？
凯文・迪尔
游戏人工智能应该只关乎一件事：使开发者能够为玩家创造引人入胜的体验。我们使用的每一种技术、每一个技巧、每一个编码的算法，都应该支持这一单一目标。
维基百科对人工智能（或 AI）的定义如下：“对智能体的研究和设计”，其中智能体是 “一个感知其环境并采取行动以最大限度地提高其成功机会的系统”。这当然不是该术语的唯一定义 ——“人工智能” 是一个众所周知难以定义的术语 —— 但它确实准确地描述了我们大学中研究和教授的许多人工智能。我们将使用 “学术人工智能” 这个术语来描述当今通常教授的人工智能。
电影动画师经常将他们创造的人工生命描述为生命的幻觉 —— 这句话被认为起源于华特・迪士尼。这是一个非常不同的目标。卡通中的角色不一定 “采取行动以最大限度地提高他们的成功机会”；例如，威利狼很多时候恰恰相反。相反，他们试图在观众中产生一种对其真实性的本能信念（尽管他们显然是人造的），并创造一种引人入胜的体验，这就是电影的全部意义所在。
每款游戏都不同，游戏对人工智能的需求也差异很大。话虽如此，游戏人工智能的目标通常与迪士尼对人工生命的看法更相似，而与经典的学术人工智能观点不太相同。像卡通一样，游戏是为娱乐而创建的。像卡通一样，游戏不是关于最大化成功、认知建模或真正的智能，而是关于讲述一个故事、创造一种体验、创造智能的幻觉 。在某些情况下，我们为创造这种幻觉所需的技术可以借鉴学术人工智能，但在许多情况下它们是不同的。我们使用 “游戏人工智能” 这个术语来描述专注于创造智能外观并为观众创造特定体验的人工智能，而不是专注于创造人类存在的真正智能。
1.2 创造体验
人们常说，游戏人工智能的目标不是最大化成功的机会，而是最大化玩家的乐趣。这当然可以是人工智能的目标，但它可能不是最好的定义。一方面，就像 “人工智能” 这个术语一样，“乐趣” 是一个众所周知难以定义的词。另一方面，并非所有游戏都关乎乐趣。有些游戏是关于讲述一个故事，或者是关于它们所包含的非常酷的角色。其他游戏是关于创造一种兴奋、冒险、悬疑甚至恐惧的感觉（如恐怖电影）。还有一些游戏是关于给玩家一种赋权感，让他（或她）感觉自己是 “大人物”。
唯一普遍正确的是，游戏是关于为玩家创造一种特定的体验 —— 无论这种体验是什么。游戏人工智能（以及游戏的其他任何部分）的目的是支持这种体验。因此，适合使用的技术仅仅是那些最能带来所需体验的技术 —— 不多也不少。
1.2.1 沉浸感的维持
玩家是我们为他们创造体验的自愿参与者。他们想要相信我们的幻觉，因此愿意暂时搁置他们通常对这些明显人造的角色和事件所感受到的自然怀疑。也就是说，我们有责任提供一种足够引人入胜的幻觉，使他们能够做到这一点 —— 也就是说，维持玩家的沉浸感。每当用户认为并对人工智能做出反应就好像它是真实的，即使底层算法实际上非常简单，我们就成功了。每当人工智能的某些行动（或不行动）提醒用户人工智能只是一个机器程序，而不是真实的，我们就失败了。ELIZA—— 约瑟夫・维森鲍姆于 1964 年开发的人工智能心理学家—— 既展示了用一个简单的算法捕捉玩家信念是多么容易，也展示了当算法行为不当时，你会多么迅速地失去这种信念。
因为他们是体验的自愿参与者，并且由于人类思维的工作方式，玩家实际上非常宽容。只要人工智能产生的行为基本合理，玩家的大脑就会为人工智能的决策想出解释，这些解释往往非常复杂 —— 比人工智能内部真正发生的事情要复杂得多 —— 但也从根本上引人入胜且可信。事实上，在某种程度上，构建一个思考过度的人工智能可能是一个错误。不仅过度设计人工智能会浪费宝贵的开发时间，而且还可能导致一个角色执行的行动，虽然对人工智能来说是合理的，但与玩家对人工智能正在做什么的心理模型不匹配。换句话说，如果你知道人工智能在想什么，这些行动是有意义的 —— 但当然，玩家不可能知道。结果，那些精心选择的决策最终看起来是随机的或完全错误的。
我们绝对必须不惜一切代价避免的一件事是人工愚蠢 —— 也就是说，选择一个看起来明显错误或根本没有意义的行动。常见的例子包括走进墙壁、卡在几何形状中或忽略正在向你射击的玩家。即使是一些实际人类会表现出的行为也应该避免，因为当由人工智能控制的角色表现出这些行为时，它们看起来不像人类。例如，人类经常改变主意 —— 但当人工智能这样做时，它往往给人一种算法错误的印象，而不是对情况的重新评估。
解决人工愚蠢问题的一个方法是简单地使人工智能更好 —— 但玩家的期望可能非常多样化，以至于很难始终满足他们所有的期望。因此，已经使用了各种其他方法。在一些游戏中 —— 僵尸游戏就是一个很好的例子 —— 角色被故意设计得有点愚蠢或古怪，这样他们的奇怪之处就更容易被接受。在其他游戏中，角色使用简短的口头台词，有时称为 “叫喊”，来向玩家提示正在发生的事情。例如，他们可能会喊 “手榴弹！” 或 “我被击中了！” 这些并不是真正用来与其他人工智能角色交流的（我们通过在代码中传递消息来实现），而是向玩家解释他们的行动。一些游戏（如《模拟人生》或《动物园大亨》）甚至会在角色的头上放置图标，表明内部正在发生的事情。《Creatures》是一款因其开创性的人工智能而在发布 15 年后仍为人所知的游戏，当一个生物改变主意时，它甚至会使用一个 “困惑” 的图标来表明行为的改变是故意的。
1.2.2 反应性、非确定性和作者控制
关于各种架构以及哪种架构最适合游戏人工智能，已经有了很多讨论。事实上，本书的整个部分都致力于此目的。人们从学术人工智能中可能得出的第一个想法是构建一个具有对所需体验的启发式定义的人工智能，然后使用机器学习来优化这种体验。这种方法存在几个问题，但最明显的是，体验通常是由游戏设计师定义的 —— 他可能是也可能不是程序员 —— 使用模糊的人类语言术语。你如何编写一个启发式函数来最大化 “乐趣”、“兴奋” 或 “酷态度”？
这并不是说启发式函数毫无用处 —— 事实上，基于效用的人工智能方法是更常见的方法之一，特别是对于决策更复杂的游戏（例如策略游戏和模拟游戏，如《模拟人生》或《动物园大亨》）。然而，至关重要的是保持作者控制 —— 也就是说，确保人工智能的作者能够调整和微调人工智能，以确保实现所需的体验。如果我们将这种控制交给机器学习算法，就会更难确保我们得到想要的结果。
然而，还有一个相互竞争的需求，那就是我们希望我们的角色具有反应性 —— 也就是说，能够感知环境并选择适合游戏中微妙、时刻变化的情况的行动。反应性和作者控制并不相互排斥。你可以构建一个具有反应性的系统，但因为你控制了它在做出决策时评估情况的方式，所以它仍然提供作者控制。然而，控制一个反应性的人工智能更复杂，因为作为开发者，你必须思考你的更改将如何改变人工智能的决策，而不是简单地直接改变角色的行为。
这里没有一个单一的正确答案。一些游戏（如策略游戏或《模拟人生》等游戏）需要更多的反应性，而其他游戏（如《魔兽世界》）则故意做出设计决策，使用更重脚本的人工智能，为玩家提供精心制作但高度可预测的体验。两者都没有错 —— 每种类型都有优秀的游戏 —— 但提供的体验不同，这是你在选择人工智能方法时需要考虑的事情。某些流行的人工智能架构在作者控制和反应性之间的权衡。
有许多流行的游戏人工智能架构，本书后面将讨论其中的许多。有些提供更好的反应性，而其他一些则允许更直接的作者控制。图 1.1 显示了一个粗略的图表，给出了几种最流行的游戏人工智能架构在这方面的一些指示。然而，请记住，每个架构都有自己的优点、缺点和特性。这仅作为一个粗略的指导方针。
值得注意的是，机器学习仅因其在学术界的流行而被放在图表上。很少有游戏将机器学习用于其核心人工智能。此外，行为树故意从该图表中省略。这是因为行为树的性能在很大程度上取决于所使用的决策组件的类型。如果这些组件都很简单，例如达米安・伊斯拉（Damian Isla）最初设想的那些 ，那么行为树与有限状态机落在大致相同的空间中。然而，行为树的一个巨大优势是，每个节点都可以包含最适合的决策逻辑，允许你为每个单独的决策使用最合适的架构。
选择人工智能架构时的另一个复杂因素是非确定性。对于许多游戏，我们希望为我们的角色添加一定程度的随机性，以便他们不会被玩家预测（并且很可能被利用）。同时，我们不希望人工智能选择一个明显错误的行动，因此我们需要确保我们的随机选择仍然是合理的。一些架构更有利于在组合中添加一些随机性（特别是行为树和基于效用的架构很好地处理了这一点），因此这是你在设计游戏时可能需要考虑的另一个因素。
1.2.3 简单性和可扩展性
作者控制的需求和避免人工愚蠢都要求游戏人工智能的配置是一个迭代过程。配置一个人工智能，使其能够处理每一种可能的情况 —— 或者至少是每一种可能的情况 —— 同时传达作者的意图并提供引人入胜、可信的现实行为，这太难在第一次尝试时就做好。相反，有必要反复测试人工智能，找到最严重的问题，纠正它们，然后再次测试。
布莱恩・克尼汉（Brian Kernighan），Unix 和 C 编程语言的共同开发者，据说曾说过：“调试代码的难度是编写代码的两倍。因此，如果你尽可能巧妙地编写代码，那么根据定义，你还不够聪明来调试它”。对于游戏人工智能来说，这一点更是加倍正确。对代码的任何更改都可能产生意想不到的副作用。也就是说，你可能在一个地方修复了一个错误或平衡问题，却在其他地方导致了更微妙的问题。一个更简单的底层算法意味着你可以在头脑中容纳更多的人工智能。因此，你将能够更全面地设想更改的所有副作用，你的开发将更安全、更快速，最终结果将更精致（并且，用一个更好的术语来说，更 “有趣” 可玩）。
如果你看看游戏中常用的决策算法 —— 有限状态机、脚本、行为树、基于权重的随机、甚至面向目标的行动规划 —— 这些算法本身都非常简单。建立在这些框架之上的配置可能确实很复杂，但底层代码简单、易于理解、易于跟踪和调试。
然而，有一个警告。许多简单算法（有限状态机是典型的例子）随着人工智能的增长扩展性很差。在有限状态机的情况下，状态转换的数量随着状态的数量呈指数增长。显然，这很快就会变得难以管理。因此，一个真正优雅的架构不仅要易于理解，还要易于使用 —— 这意味着，除其他外，它必须具有良好的扩展性。
1.2.4 技巧和作弊
关于游戏人工智能的作弊问题已经有很多说法，但我们似乎甚至无法就 “作弊” 是什么达成一致。让人工智能角色比玩家稍微强大一点是作弊吗？如果我给他们一个物品来证明这种加成是合理的呢？在策略游戏中给人工智能角色一个经济加成，让他们能够更便宜地购买单位是作弊吗？如果我允许玩家选择加成的大小，并称之为 “难度级别” 呢？
有一个很棒的故事，我最近在与暴雪策略游戏标题的人工智能负责人鲍勃・菲奇（Bob Fitch）的谈话中证实了这个故事 。显然，原版《魔兽争霸》的场景人工智能只会等待固定的时间，然后开始生成一波单位来攻击你。它会在灰色迷雾的边缘生成这些单位 —— 也就是说，就在你的单位可见范围之外。它会继续生成单位，直到你的防御几乎被压倒 —— 然后它会停止，让你清理剩下的单位并让你赢得战斗。
这种方法似乎相当明确地跨越了界限，进入了 “作弊” 的领域。人工智能不必担心建造建筑物、节省资金或招募单位 —— 它只是生成它需要的任何东西。另一方面，想想由此产生的体验。无论你在游戏中表现得好还是差，它都会为你创造一场史诗般的战斗 —— 一场将你推向能力极限的战斗，但最终你会战胜一切困难取得胜利。
当然，这种作弊方式也有一个阴暗面，那就是只有在玩家保持无知的情况下才能奏效。如果玩家发现了你在做什么，那么他们的体验就会完全不同 —— 而且没有人喜欢被光顾。不幸的是，如今，特别是随着互联网的出现，玩家比 1994 年时更难被愚弄（并且也更不宽容）。
另一种作弊类型纯粹是信息性的。也就是说，人工智能是否必须感知到一个单位才能知道它的存在和位置？问题是，虽然进行视线检查以确定可见性相当直接，但记住你所看到的并使用它来预测未来事件要困难得多。换句话说，如果我看到一个单位，但然后它离开了视线，我如何记住它的存在？我如何猜测它的位置？如果我稍后看到同一类型的单位，我如何知道它是同一个单位还是不同的单位？人类在这种事情上相当擅长，但要做好它需要对手建模、直觉和纯粹的猜测。这些是计算机众所周知不擅长的事情。
不幸的是，对于许多类型的游戏来说，人工智能具有合理预测资源位置、敌人实力和位置等事物的能力至关重要。如果玩家弄错了，他们就会输 —— 但对大多数玩家来说，这是一种可以接受的失败。“我只是从来没有找到任何我可以利用的东西”，或者 “你这次骗了我 —— 但下次我会抓住你！” 他们开始另一局游戏，或从保存点重新加载，如果有什么的话，挑战会把他们拉回到游戏中。另一方面，如果人工智能弄错了，那么玩家将轻松获胜，根本不会体验到任何重大挑战。他们不会想：“嗯，人工智能可能只是运气不好。” 他们会想：“天哪，那个人工智能太愚蠢了。” 一旦他们开始认为人工智能 “愚蠢”，你所追求的体验几乎肯定就失去了。
最终，是否编写作弊的人工智能的决定是一个相对简单的决定。你应该让人工智能作弊，当且仅当它会改善玩家的体验 —— 但请记住，如果你作弊并被抓住，这本身就会改变玩家的体验，而且通常不是变得更好。在《可汗 2》（Kohan 2）中，这是一款因其人工智能而获得赞誉的即时战略游戏，我们有两个微妙的作弊。首先，在探索时，我们每隔 30 秒左右给人工智能一个随机机会作弊，探索我们知道有好东西可发现的区域。这有助于我们避免游戏中人工智能只是碰巧没有足够早地找到附近任何资源的情况。其次是跟踪一个区域中敌人力量的大致数量（但不是单位的具体位置）。这使我们能够为我们的攻击和防御目标分配合理的力量数量，并避免派遣单位进行徒劳的追逐。没有一个评论家发现这两个作弊，事实上，正如前面所暗示的，他们归因于人工智能的许多智能行为实际上只是我们作弊方式的副作用。
1.3 结论
学术人工智能可以关乎许多事情。它可以关乎解决难题、重现人类智能、建模人类认知以更多地了解我们的大脑如何工作、优化复杂操作环境（例如自主机器人）中的性能，或者任何其他极具挑战性和有价值的追求。所有这些事情都很难且值得做 —— 但适用于它们的解决方案不一定适用于游戏。
游戏人工智能应该只关乎一件事：使开发者能够为玩家创造引人入胜的体验 —— 一种让玩家愿意花时间在游戏上，愿意购买扩展包和续作的体验，如果成功，这将不可避免地实现。
本书的其余部分充满了已被证明对我们行业有效的提示、技巧、技术和解决方案。游戏时间表很紧，几乎没有错误余地，如果人工智能在发布时不能正常工作，很少有机会延期。此外，仅仅为游戏构建一个引人入胜的人工智能就足够具有挑战性了。我们既没有时间也没有意愿去解决我们不需要解决的难题，也没有意愿去重新发明已经找到的解决方案。考虑到这些挑战，希望其中的一些方法也能对你有所帮助。